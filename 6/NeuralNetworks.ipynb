{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label      1      2       3       4        5        6       7        8  \\\n",
       "0     M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "1     M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "2     M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "3     M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "4     M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "        9  ...     21     22      23      24      25      26      27      28  \\\n",
       "0  0.2419  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.1812  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.2069  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.2597  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.1809  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       29       30  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = pd.read_csv(\"../datasets/cancer.csv\")\n",
    "print(cancer_data.shape)\n",
    "cancer_labels = np.array([1 if l == 'M' else 0 for l in cancer_data['label'].values])\n",
    "cancer_features = cancer_data.drop(['label'], axis=1).values\n",
    "cancer_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_:</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_:  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  label  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = pd.read_csv(\"../datasets/spam.csv\")\n",
    "print(spam_data.shape)\n",
    "spam_labels = spam_data['label'].values\n",
    "spam_features = spam_data.drop(['label'], axis=1).values\n",
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, X, y, lr=0.1, max_iter=100, X_eval=None, y_eval=None, acc=None):\n",
    "        if self.w is None:\n",
    "            self.w = np.zeros(X.shape[1]) #np.random.random(X.shape[1])\n",
    "        if X_eval is not None and y_eval is not None:\n",
    "            best_score = (self.predict(X_eval) == y_eval).mean()\n",
    "        for i in range(max_iter):\n",
    "            grad = np.zeros(X.shape[1])\n",
    "            F = X @ self.w\n",
    "            for i in range(len(X)):\n",
    "                grad += (y[i] - (1 / (1 + np.exp(-F[i])))) * X[i]\n",
    "#             print(self.w)\n",
    "            self.w += lr * grad\n",
    "            if X_eval is not None and y_eval is not None:\n",
    "                score = (self.predict(X_eval) == y_eval).mean()\n",
    "                if acc is not None:\n",
    "                    acc.append(score)\n",
    "#                 print(\"Scores:\", score, best_score)\n",
    "#                 if score <= best_score:\n",
    "#                     self.w -= lr * grad\n",
    "#                     self.fitted = True\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     best_score = score\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return X @ self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = self.predict_proba(X)\n",
    "        return np.array([1 if y[i] > 0.5 else 0 for i in range(len(y))])\n",
    "\n",
    "    def coeffs(self):\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_application(X, y):\n",
    "    X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, train_size=0.7)\n",
    "    model = LogisticRegression()\n",
    "    scores = []\n",
    "    model.fit(X_tr, y_tr, lr=0.0001, max_iter=10, X_eval=X_te, y_eval=y_te, acc=scores)\n",
    "#     while not model.fitted and len(scores) < 10:\n",
    "#         model.fit(X_tr, y_tr, lr=0.00001, max_iter=1, X_eval=X_te, y_eval=y_te, scores=scores)\n",
    "#         scores.append((model.predict(X_te) == y_te).mean())\n",
    "#         print(model.predict(X_tr).mean())\n",
    "#         print(scores)\n",
    "    plt.scatter(range(len(scores)), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_reg_application(cancer_features, cancer_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_reg_application(spam_features, spam_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = pd.read_csv(\"../datasets/mnist.csv\")\n",
    "mnist_labels = mnist_data[\"label\"].values\n",
    "mnist_features = mnist_data.drop([\"label\"], axis=1).values.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 28, 28)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip ../datasets/notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png\n",
      "Skip ../datasets/notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png\n"
     ]
    }
   ],
   "source": [
    "def read_notMnist():\n",
    "    data = []\n",
    "    for root, dirs, files in os.walk(\"../datasets/notMNIST_small\"):\n",
    "        for file in files:\n",
    "            if file[-3:] == 'png':\n",
    "                data.append((root + os.sep + file, root[-1]))\n",
    "    features = []\n",
    "    labels = []\n",
    "    lab_dict = {}\n",
    "    for pic, lab in data:\n",
    "        if lab not in lab_dict:\n",
    "            lab_dict[lab] = len(lab_dict)\n",
    "        try:\n",
    "            features.append(imageio.imread(pic).reshape(1, 28, 28))\n",
    "            labels.append(lab_dict[lab])\n",
    "        except:\n",
    "            print(\"Skip\", pic)\n",
    "    return np.array(features), np.array(labels), lab_dict\n",
    "\n",
    "notmnist_features, notmnist_labels, notmnist_labels_map = read_notMnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, act):\n",
    "        super(Net, self).__init__()\n",
    "        self.act = act\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3)\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3)\n",
    "        self.fc1 = nn.Linear(8 * 22 * 22, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = self.act(self.conv3(x))\n",
    "        x = x.view(-1, 8 * 22 * 22)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(X, y):\n",
    "    tx = torch.stack([torch.Tensor(i) for i in X])\n",
    "    ty = torch.Tensor(y).long()\n",
    "    dataset = TensorDataset(tx, ty)\n",
    "    return DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "def fit_nn_epoch(net, dataloader, optimizer, criterion):\n",
    "    running_loss = 0.0\n",
    "    epoch = 1\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "def predict(net, dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    images, labels = dataiter.next()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    return predicted\n",
    "\n",
    "def accuracy(net, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "def fit_images(X, y, activation, epochs=2):\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, train_size=0.7)\n",
    "    trainloader = make_dataloader(X_tr, y_tr)\n",
    "    testloader = make_dataloader(X_te, y_te)\n",
    "    \n",
    "    net = Net(F.relu)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    epochs\n",
    "    print(accuracy(net, testloader))\n",
    "    for epoch in range(epochs):\n",
    "        fit_nn_epoch(net, trainloader, optimizer, criterion)\n",
    "        print(accuracy(net, testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 1.135\n",
      "[2,   400] loss: 0.580\n",
      "[2,   600] loss: 0.473\n",
      "[2,   800] loss: 0.365\n",
      "[2,  1000] loss: 0.353\n",
      "[2,  1200] loss: 0.394\n",
      "[2,  1400] loss: 0.296\n",
      "[2,  1600] loss: 0.229\n",
      "0.928\n",
      "[2,   200] loss: 0.222\n",
      "[2,   400] loss: 0.195\n",
      "[2,   600] loss: 0.207\n",
      "[2,   800] loss: 0.186\n",
      "[2,  1000] loss: 0.191\n",
      "[2,  1200] loss: 0.165\n",
      "[2,  1400] loss: 0.180\n",
      "[2,  1600] loss: 0.164\n",
      "0.9606666666666667\n"
     ]
    }
   ],
   "source": [
    "fit_images(mnist_features, mnist_labels, F.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08833333333333333\n",
      "[2,   200] loss: 1.362\n",
      "[2,   400] loss: 0.738\n",
      "[2,   600] loss: 0.556\n",
      "[2,   800] loss: 0.315\n",
      "[2,  1000] loss: 0.300\n",
      "[2,  1200] loss: 0.373\n",
      "[2,  1400] loss: 0.237\n",
      "[2,  1600] loss: 0.253\n",
      "0.9433333333333334\n",
      "[2,   200] loss: 0.176\n",
      "[2,   400] loss: 0.215\n",
      "[2,   600] loss: 0.171\n",
      "[2,   800] loss: 0.208\n",
      "[2,  1000] loss: 0.178\n",
      "[2,  1200] loss: 0.183\n",
      "[2,  1400] loss: 0.178\n",
      "[2,  1600] loss: 0.177\n",
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "fit_images(mnist_features, mnist_labels, F.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.102\n",
      "[2,   200] loss: 1.190\n",
      "[2,   400] loss: 0.629\n",
      "[2,   600] loss: 0.448\n",
      "[2,   800] loss: 0.382\n",
      "[2,  1000] loss: 0.332\n",
      "[2,  1200] loss: 0.370\n",
      "[2,  1400] loss: 0.304\n",
      "[2,  1600] loss: 0.280\n",
      "0.8393333333333334\n",
      "[2,   200] loss: 0.226\n",
      "[2,   400] loss: 0.208\n",
      "[2,   600] loss: 0.227\n",
      "[2,   800] loss: 0.164\n",
      "[2,  1000] loss: 0.172\n",
      "[2,  1200] loss: 0.194\n",
      "[2,  1400] loss: 0.156\n",
      "[2,  1600] loss: 0.179\n",
      "0.946\n"
     ]
    }
   ],
   "source": [
    "fit_images(mnist_features, mnist_labels, F.tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10039159843360626\n",
      "[2,   200] loss: 1.524\n",
      "[2,   400] loss: 1.127\n",
      "[2,   600] loss: 0.876\n",
      "[2,   800] loss: 0.724\n",
      "[2,  1000] loss: 0.746\n",
      "[2,  1200] loss: 0.707\n",
      "[2,  1400] loss: 0.595\n",
      "[2,  1600] loss: 0.548\n",
      "[2,  1800] loss: 0.441\n",
      "[2,  2000] loss: 0.556\n",
      "[2,  2200] loss: 0.550\n",
      "[2,  2400] loss: 0.519\n",
      "[2,  2600] loss: 0.516\n",
      "[2,  2800] loss: 0.451\n",
      "[2,  3000] loss: 0.421\n",
      "[2,  3200] loss: 0.392\n",
      "0.8659665361338554\n",
      "[2,   200] loss: 0.381\n",
      "[2,   400] loss: 0.358\n",
      "[2,   600] loss: 0.329\n",
      "[2,   800] loss: 0.394\n",
      "[2,  1000] loss: 0.319\n",
      "[2,  1200] loss: 0.378\n",
      "[2,  1400] loss: 0.344\n",
      "[2,  1600] loss: 0.307\n",
      "[2,  1800] loss: 0.381\n",
      "[2,  2000] loss: 0.325\n",
      "[2,  2200] loss: 0.343\n",
      "[2,  2400] loss: 0.387\n",
      "[2,  2600] loss: 0.304\n",
      "[2,  2800] loss: 0.375\n",
      "[2,  3000] loss: 0.274\n",
      "[2,  3200] loss: 0.324\n",
      "0.9047703809184763\n"
     ]
    }
   ],
   "source": [
    "fit_images(notmnist_features, notmnist_labels, F.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
